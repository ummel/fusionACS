<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Methods and formulae • fusionACS</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Methods and formulae">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-secondary" data-bs-theme="dark" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">fusionACS</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.0.11</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="../articles/data.html">Data</a></li>
<li class="nav-item"><a class="nav-link" href="../articles/usage.html">Usage</a></li>
<li class="active nav-item"><a class="nav-link" href="../articles/methods.html">Methods</a></li>
<li class="nav-item"><a class="nav-link" href="../articles/publications.html">Publications</a></li>
<li class="nav-item"><a class="nav-link" href="../articles/faq.html">FAQ</a></li>
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/ummel/fusionACS/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>Methods and formulae</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/ummel/fusionACS/blob/HEAD/vignettes/methods.Rmd" class="external-link"><code>vignettes/methods.Rmd</code></a></small>
      <div class="d-none name"><code>methods.Rmd</code></div>
    </div>

    
    
<div class="section level2">
<h2 id="fusion-methodology">Fusion methodology<a class="anchor" aria-label="anchor" href="#fusion-methodology"></a>
</h2>
<p>A complete description of the fusionACS methodology is provided by
<span class="citation">Ummel et al. (<a href="#ref-Ummel2024">2024</a>)</span>. For a given donor survey, the
data processing and analysis “pipeline” consists of the following
steps:</p>
<ol style="list-style-type: decimal">
<li>Ingest raw survey data to produce standardized microdata and
documentation.</li>
<li>Harmonize variables in the donor survey with conceptually-similar
variables in the ACS.</li>
<li>Prepare clean, structured, and consistent donor and ACS
microdata.</li>
<li>Train machine learning models on the donor microdata.</li>
<li>Fuse the donor’s unique variables to ACS microdata.</li>
<li>Validate the fused microdata.</li>
<li>Analyze the fused microdata to calculate estimates and margins of
error.</li>
</ol>
<p>Steps 1–3 are part of the fusionData package, and Steps 4–6 are
carried out using the fusionModel package. These steps are carried out
by the fusionACS team internally, and there is generally no reason for a
practitioner to use the associated packages.</p>
<p>The key functionality of Step 7 is provided by the fusionACS package
documented on this site.</p>
<p>The figure below from <span class="citation">Ummel et al. (<a href="#ref-Ummel2024">2024</a>)</span> shows how the various input data
sources fit together.</p>
<p><img src="../reference/figures/Ummel2024.png"></p>
<p>The spatial data consists of a wide range of place-specific predictor
variables that can be merged to both donor and ACS microdata on the
basis of respondent location. These are used to augment the harmonized,
respondent-level predictors available to the machine learning
models.</p>
</div>
<div class="section level2">
<h2 id="urbanpop-integration">UrbanPop integration<a class="anchor" aria-label="anchor" href="#urbanpop-integration"></a>
</h2>
<p>Recent work integrating ORNL UrbanPop represents a significant
advancement in the ability of fusionACS to generate high-resolution
estimates across space.</p>
<p>UrbanPop is a synthetic population data product produced by Oak Ridge
National Laboratory <span class="citation">(<a href="#ref-Tuccillo2023">Tuccillo et al. 2023</a>)</span>. It provides
probabilistic estimates of the location (block group) of each ACS
respondent household. Specifically, for each block group, ACS PUMS
respondent households are re-weighted to replicate published ACS Summary
File tables for key demographic, economic, employment, mobility, and
housing variables.</p>
<p>Merging fusionACS microdata with UrbanPop (linking on PUMS respondent
ID) results in simulated block group populations for which we can
observe both ACS and donor survey variables. This allows fusionACS +
UrbanPop to generate estimates for geographic areas smaller than the
Public Use Microdata Areas (PUMA’s) disclosed in the ACS PUMS.</p>
<p>Since UrbanPop assigns each ACS household to multiple block groups
(about 8, on average) the merged microdata can become quite large. The
public pseudo-sample includes only a partial, structured sample of the
UrbanPop weights. This helps keep the public data release fully
functional but also a manageable size. Analyses computed on the complete
database inside the Yale High Performance Computing (HPC) facility
utilize the complete UrbanPop dataset to derive production-level
estimates.</p>
</div>
<div class="section level2">
<h2 id="point-estimates-and-uncertainty">Point estimates and uncertainty<a class="anchor" aria-label="anchor" href="#point-estimates-and-uncertainty"></a>
</h2>
<p>A fusionACS <em>analysis</em> consists of a request for an
<em>estimate</em> of a particular variable across one or more
sub-populations. Estimates can be means, medians, sums, proportions, or
counts. For example, “Mean household electricity consumption in Chicago,
by census tract”; or “Proportion of low-income households in Atlanta
without air conditioning”.</p>
<p>In addition to a point estimate, fusionACS also returns the
associated uncertainty or <em>margin of error</em>. Uncertainty in the
underlying machine learning models is captured through the production of
<em>M</em> unique <em>implicates</em> (typically 20). Each implicate is
a unique and equally-plausible simulation of the fused variables given
uncertainty in the underlying fusion process. The public pseudo-sample
includes only a single implicate (<em>M=1</em>).</p>
<p>By assessing the variance both within and across implicates, it is
possible to calculate the margin of error associated with any given
point estimate.</p>
<div class="section level3">
<h3 id="pooled-variance">Pooled variance<a class="anchor" aria-label="anchor" href="#pooled-variance"></a>
</h3>
<p>For any given fusionACS analysis, the point estimates and associated
margin of error are calculated using the technique of <span class="citation">Rubin (<a href="#ref-Rubin1987">1987</a>)</span>. The
point estimate,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mover><mi>θ</mi><mo accent="true">‾</mo></mover><annotation encoding="application/x-tex">\bar{\theta}</annotation></semantics></math>,
is the mean of the individual estimates calculated for each of the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>M</mi><annotation encoding="application/x-tex">M</annotation></semantics></math>
implicates:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover><mi>θ</mi><mo accent="true">‾</mo></mover><mo>=</mo><mfrac><mn>1</mn><mi>M</mi></mfrac><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>M</mi></munderover><msub><mover><mi>θ</mi><mo accent="true">̂</mo></mover><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">
\bar{\theta} = \frac{1}{M} \sum_{i=1}^{M} \hat{\theta}_i
</annotation></semantics></math> The variance of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mover><mi>θ</mi><mo accent="true">‾</mo></mover><annotation encoding="application/x-tex">\bar{\theta}</annotation></semantics></math>
is calculated by “pooling” the variance both within and between
samples:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mtext mathvariant="normal">Var</mtext><mtext mathvariant="normal">combined</mtext></msub><mo>=</mo><mfrac><mn>1</mn><mi>M</mi></mfrac><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>M</mi></munderover><mtext mathvariant="normal">Var</mtext><mrow><mo stretchy="true" form="prefix">(</mo><msub><mover><mi>θ</mi><mo accent="true">̂</mo></mover><mi>i</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>+</mo><mrow><mo stretchy="true" form="prefix">(</mo><mn>1</mn><mo>+</mo><mfrac><mn>1</mn><mi>M</mi></mfrac><mo stretchy="true" form="postfix">)</mo></mrow><msub><mtext mathvariant="normal">Var</mtext><mtext mathvariant="normal">between</mtext></msub></mrow><annotation encoding="application/x-tex">
\text{Var}_{\text{combined}} = \frac{1}{M} \sum_{i=1}^{M} \text{Var}( \hat{\theta}_i ) + \left( 1 + \frac{1}{M} \right) \text{Var}_{\text{between}}
</annotation></semantics></math></p>
<p>where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mtext mathvariant="normal">Var</mtext><mtext mathvariant="normal">between</mtext></msub><annotation encoding="application/x-tex">\text{Var}_{\text{between}}</annotation></semantics></math>
is the “between-sample” variance of the individual estimates:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mtext mathvariant="normal">Var</mtext><mtext mathvariant="normal">between</mtext></msub><mo>=</mo><mfrac><mn>1</mn><mrow><mi>M</mi><mo>−</mo><mn>1</mn></mrow></mfrac><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>M</mi></munderover><msup><mrow><mo stretchy="true" form="prefix">(</mo><msub><mover><mi>θ</mi><mo accent="true">̂</mo></mover><mi>i</mi></msub><mo>−</mo><mover><mi>θ</mi><mo accent="true">‾</mo></mover><mo stretchy="true" form="postfix">)</mo></mrow><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">
\text{Var}_{\text{between}} = \frac{1}{M - 1} \sum_{i=1}^{M} \left( \hat{\theta}_i - \bar{\theta} \right)^2
</annotation></semantics></math></p>
<p>and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext mathvariant="normal">Var</mtext><mrow><mo stretchy="true" form="prefix">(</mo><msub><mover><mi>θ</mi><mo accent="true">̂</mo></mover><mi>i</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\text{Var}( \hat{\theta}_i )</annotation></semantics></math>
refers to the “within-sample” variances of the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>M</mi><annotation encoding="application/x-tex">M</annotation></semantics></math>
individual estimates; i.e. the square of the standard error
[<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext mathvariant="normal">SE</mtext><msup><mrow><mo stretchy="true" form="prefix">(</mo><mover><mi>θ</mi><mo accent="true">̂</mo></mover><mo stretchy="true" form="postfix">)</mo></mrow><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">\text{SE}( \hat{\theta} )^2</annotation></semantics></math>].</p>
</div>
<div class="section level3">
<h3 id="within-sample-standard-errors">Within-sample standard errors<a class="anchor" aria-label="anchor" href="#within-sample-standard-errors"></a>
</h3>
<p>The calculation of within-sample standard errors depends on the type
of estimate requested. To calculate the standard error of a mean
estimate for a sample of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>n</mi><annotation encoding="application/x-tex">n</annotation></semantics></math>
observations with frequency weights
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>w</mi><mi>i</mi></msub><annotation encoding="application/x-tex">w_i</annotation></semantics></math>:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mi>E</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mover><mi>θ</mi><mo accent="true">̂</mo></mover><mtext mathvariant="normal">mean</mtext></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><msqrt><mrow><mfrac><mrow><mo>∑</mo><msub><mi>w</mi><mi>i</mi></msub><msup><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>−</mo><msub><mover><mi>x</mi><mo accent="true">‾</mo></mover><mi>w</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mn>2</mn></msup></mrow><mrow><mo>∑</mo><msub><mi>w</mi><mi>i</mi></msub><mo>−</mo><mn>1</mn></mrow></mfrac><mo>⋅</mo><mfrac><mn>1</mn><msub><mi>n</mi><mtext mathvariant="normal">eff</mtext></msub></mfrac></mrow></msqrt></mrow><annotation encoding="application/x-tex">
SE(\hat{\theta}_{\text{mean}}) = \sqrt{ \frac{ \sum w_i (x_i - \bar{x}_w)^2 }{ \sum w_i - 1 } \cdot \frac{1}{n_{\text{eff}}} }
</annotation></semantics></math> where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mover><mi>x</mi><mo accent="true">‾</mo></mover><mi>w</mi></msub><annotation encoding="application/x-tex">\bar{x}_w</annotation></semantics></math>
is the weighted mean and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>n</mi><mtext mathvariant="normal">eff</mtext></msub><annotation encoding="application/x-tex">n_{\text{eff}}</annotation></semantics></math>
is the effective sample size calculated from the observation
weights:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>n</mi><mtext mathvariant="normal">eff</mtext></msub><mo>=</mo><mfrac><msup><mrow><mo stretchy="true" form="prefix">(</mo><mo>∑</mo><msub><mi>w</mi><mi>i</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mn>2</mn></msup><mrow><mo>∑</mo><msubsup><mi>w</mi><mi>i</mi><mn>2</mn></msubsup></mrow></mfrac></mrow><annotation encoding="application/x-tex">
n_{\text{eff}} = \frac{ \left( \sum w_i \right)^2 }{ \sum w_i^2 }
</annotation></semantics></math> The observations weights either come
directly from the ACS PUMS or from ORNL UrbanPop, depending on the level
of geographic detail required by an analysis. By default,
<code><a href="../reference/assemble.html">assemble()</a></code> automatically chooses the appropriate weights.
The public pseudo-sample includes only a partial, structured sample of
the UrbanPop weights.</p>
<p>The use of the “effective sample size”
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>n</mi><mtext mathvariant="normal">eff</mtext></msub><mo stretchy="true" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">(n_{\text{eff}})</annotation></semantics></math>
– rather than sample size
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>n</mi><annotation encoding="application/x-tex">n</annotation></semantics></math>
– helps capture additional uncertainty in the sample weights themselves
<span class="citation">(<a href="#ref-Kish1965">Kish 1965</a>; <a href="#ref-Lumley2010">Lumley 2010</a>)</span>. In general, the smaller
the target population the greater the “unevenness” of the observed
sample weights, leading to
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>n</mi><mtext mathvariant="normal">eff</mtext></msub><mo>&lt;</mo><mi>n</mi></mrow><annotation encoding="application/x-tex">n_{\text{eff}}&lt;n</annotation></semantics></math>,
and a corresponding increase in the standard error.</p>
<p>This approach differs from the “Successive Differences Replication”
(SDR) method typically used to calculate the margin of error when
working with the ACS PUMS <span class="citation">(<a href="#ref-Census2020">U.S. Census Bureau 2020</a>)</span>. However, in
initial testing we find that the SDR and effective sample size
approaches yield very similar uncertainty estimates
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="true" form="prefix">(</mo><mi>c</mi><mi>o</mi><mi>r</mi><mi>r</mi><mi>e</mi><mi>l</mi><mi>a</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo>≈</mo><mn>0.9</mn><mo stretchy="true" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">(correlation \approx 0.9)</annotation></semantics></math>,
with the latter exhibiting a slight upward bias. Since SDR requires
significantly more computation, for the time being we have opted to use
the effective sample size technique instead.</p>
<p>The implementation in <em>R</em> uses the <em>collapse</em> package
<code>qsu()</code> function <span class="citation">(<a href="#ref-Krantz2025">Krantz 2025</a>)</span>, which computes the mean,
standard deviation, and sum of weights in a single pass through the data
in C/C++. This provides extremely fast calculation, even when the data
is grouped across
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>M</mi><annotation encoding="application/x-tex">M</annotation></semantics></math>
implicates and (optionally) user-specified sub-populations.</p>
<p>For median estimates, calculation of the standard error via
bootstrapping is prohibitively expensive <span class="citation">(<a href="#ref-Hahn1991">Hahn and Meeker 1991</a>)</span>. Given the need
for computational efficiency in the fusionACS context, the standard
error of the median is instead estimated using the large-sample
approximation:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mi>E</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mover><mi>θ</mi><mo accent="true">̂</mo></mover><mtext mathvariant="normal">median</mtext></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>≈</mo><mfrac><mn>1</mn><mrow><mn>2</mn><mi>f</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>m</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow></mfrac><mo>⋅</mo><mfrac><mn>1</mn><msqrt><msub><mi>n</mi><mtext mathvariant="normal">eff</mtext></msub></msqrt></mfrac></mrow><annotation encoding="application/x-tex">
SE(\hat{\theta}_{\text{median}}) \approx \frac{1}{2f(m)} \cdot \frac{1}{\sqrt{n_{\text{eff}}}}
</annotation></semantics></math> where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>m</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">f(m)</annotation></semantics></math>
is the density at the median. The formula arises from the asymptotic
variance of sample quantiles under regularity conditions <span class="citation">(<a href="#ref-Serfling1980">Serfling 1980</a>)</span>.
For speed,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>m</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">f(m)</annotation></semantics></math>
is approximated using a finite difference of the quantile function <span class="citation">(<a href="#ref-Koenker2005">Koenker
2005</a>)</span>:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>m</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>≈</mo><mfrac><mrow><msub><mi>p</mi><mn>2</mn></msub><mo>−</mo><msub><mi>p</mi><mn>1</mn></msub></mrow><mrow><mi>Q</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>p</mi><mn>2</mn></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>−</mo><mi>Q</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>p</mi><mn>1</mn></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow></mfrac></mrow><annotation encoding="application/x-tex">
f(m) \approx \frac{p_2 - p_1}{Q(p_2) - Q(p_1)}
</annotation></semantics></math></p>
<p>where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>p</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">Q(p)</annotation></semantics></math>
is the weighted quantile function, and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>p</mi><mn>1</mn></msub><annotation encoding="application/x-tex">p_1</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>p</mi><mn>2</mn></msub><annotation encoding="application/x-tex">p_2</annotation></semantics></math>
are probabilities close to the median (0.475 and 0.525, by default).
Implementation via the <em>collapse</em> package leverages a single,
radix-based ordering of the input to efficiently compute the median,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>p</mi><mn>1</mn></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">Q(p_1)</annotation></semantics></math>,
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>p</mi><mn>2</mn></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">Q(p_2)</annotation></semantics></math>.
This allows the standard error to be estimated at little additional cost
beyond computation of the median itself.</p>
<p>If
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>m</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">f(m)</annotation></semantics></math>
is undefined, the code falls back to the conservative approximation of
<span class="citation">Tukey (<a href="#ref-Tukey1977">1977</a>)</span>:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mi>E</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mover><mi>θ</mi><mo accent="true">̂</mo></mover><mtext mathvariant="normal">median</mtext></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>≈</mo><mi>S</mi><mi>E</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mover><mi>θ</mi><mo accent="true">̂</mo></mover><mtext mathvariant="normal">mean</mtext></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>⋅</mo><mfrac><mi>π</mi><mn>2</mn></mfrac></mrow><annotation encoding="application/x-tex">
SE(\hat{\theta}_{\text{median}}) \approx SE(\hat{\theta}_{\text{mean}})  \cdot \frac{\pi}{2}
</annotation></semantics></math> To calculate the standard error of a
proportion, given the previously-defined effective sample size:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mi>E</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mover><mi>θ</mi><mo accent="true">̂</mo></mover><mtext mathvariant="normal">proportion</mtext></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><msqrt><mfrac><mrow><msup><mover><mi>p</mi><mo accent="true">̂</mo></mover><mo>*</mo></msup><mrow><mo stretchy="true" form="prefix">(</mo><mn>1</mn><mo>−</mo><msup><mover><mi>p</mi><mo accent="true">̂</mo></mover><mo>*</mo></msup><mo stretchy="true" form="postfix">)</mo></mrow></mrow><msub><mi>n</mi><mtext mathvariant="normal">eff</mtext></msub></mfrac></msqrt></mrow><annotation encoding="application/x-tex">
SE(\hat{\theta}_{\text{proportion}}) = \sqrt{ \frac{ \hat{p}^*(1 - \hat{p}^*) }{ n_{\text{eff}} } }
</annotation></semantics></math></p>
<p>where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mover><mi>p</mi><mo accent="true">̂</mo></mover><mo>*</mo></msup><annotation encoding="application/x-tex">\hat{p}^*</annotation></semantics></math>
is the Agresti-Coull <span class="citation">(<a href="#ref-Agresti1998">Agresti and Coull 1998</a>)</span> adjusted
proportion derived from the weighted sample proportion
(<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mover><mi>p</mi><mo accent="true">̂</mo></mover><annotation encoding="application/x-tex">\hat{p}</annotation></semantics></math>),
assuming a 90% confidence interval
(<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>z</mi><mo>=</mo><mn>1.645</mn></mrow><annotation encoding="application/x-tex">z=1.645</annotation></semantics></math>):</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mover><mi>p</mi><mo accent="true">̂</mo></mover><mo>*</mo></msup><mo>=</mo><mfrac><mrow><mover><mi>p</mi><mo accent="true">̂</mo></mover><mo>⋅</mo><msub><mi>n</mi><mtext mathvariant="normal">eff</mtext></msub><mo>+</mo><mfrac><msup><mi>z</mi><mn>2</mn></msup><mn>2</mn></mfrac></mrow><mrow><msub><mi>n</mi><mtext mathvariant="normal">eff</mtext></msub><mo>+</mo><msup><mi>z</mi><mn>2</mn></msup></mrow></mfrac></mrow><annotation encoding="application/x-tex">
\hat{p}^* = \frac{ \hat{p} \cdot n_{\text{eff}} + \frac{z^2}{2} }{ n_{\text{eff}} + z^2 }
</annotation></semantics></math></p>
<p>This adjustment ensures a non-zero standard error when
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover><mi>p</mi><mo accent="true">̂</mo></mover><mrow><mo stretchy="true" form="prefix">(</mo><mn>1</mn><mo>−</mo><mover><mi>p</mi><mo accent="true">̂</mo></mover><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\hat{p}(1 - \hat{p})</annotation></semantics></math>
is zero; e.g. for unobserved outcomes in smaller samples. The
un-adjusted sample proportion
(<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mover><mi>p</mi><mo accent="true">̂</mo></mover><annotation encoding="application/x-tex">\hat{p}</annotation></semantics></math>)
is always returned as the point estimate.</p>
<p>For sums (numerical case) and counts (categorical case), the standard
error is a multiple of the standard error of the mean and proportion,
respectively:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mi>E</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mover><mi>θ</mi><mo accent="true">̂</mo></mover><mtext mathvariant="normal">sum</mtext></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mi>S</mi><mi>E</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mover><mi>θ</mi><mo accent="true">̂</mo></mover><mtext mathvariant="normal">mean</mtext></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>⋅</mo><mo>∑</mo><msub><mi>w</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">
SE(\hat{\theta}_{\text{sum}}) = SE(\hat{\theta}_{\text{mean}}) \cdot \sum w_i
</annotation></semantics></math></p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mi>E</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mover><mi>θ</mi><mo accent="true">̂</mo></mover><mtext mathvariant="normal">count</mtext></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mi>S</mi><mi>E</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mover><mi>θ</mi><mo accent="true">̂</mo></mover><mtext mathvariant="normal">proportion</mtext></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>⋅</mo><mo>∑</mo><msub><mi>w</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">
SE(\hat{\theta}_{\text{count}}) = SE(\hat{\theta}_{\text{proportion}}) \cdot \sum w_i
</annotation></semantics></math></p>
</div>
<div class="section level3">
<h3 id="margin-of-error">Margin of error<a class="anchor" aria-label="anchor" href="#margin-of-error"></a>
</h3>
<p>Having calculated
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mtext mathvariant="normal">Var</mtext><mtext mathvariant="normal">combined</mtext></msub><annotation encoding="application/x-tex">\text{Var}_{\text{combined}}</annotation></semantics></math>
and its component variances, the degrees of freedom is calculated using
the formula of <span class="citation">Barnard and Rubin (<a href="#ref-Barnard1999">1999</a>)</span>. Compared to the original <span class="citation">Rubin (<a href="#ref-Rubin1987">1987</a>)</span>
degrees of freedom, this formulation allows for unequal within-sample
variances and is more accurate for small samples.</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ν</mi><mo>=</mo><mrow><mo stretchy="true" form="prefix">(</mo><mi>M</mi><mo>−</mo><mn>1</mn><mo stretchy="true" form="postfix">)</mo></mrow><msup><mrow><mo stretchy="true" form="prefix">(</mo><mn>1</mn><mo>+</mo><mfrac><mrow><mfrac><mn>1</mn><mi>M</mi></mfrac><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>M</mi></munderover><mtext mathvariant="normal">Var</mtext><mrow><mo stretchy="true" form="prefix">(</mo><msub><mover><mi>θ</mi><mo accent="true">̂</mo></mover><mi>i</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><msub><mtext mathvariant="normal">Var</mtext><mtext mathvariant="normal">between</mtext></msub></mfrac><mo stretchy="true" form="postfix">)</mo></mrow><mn>2</mn></msup><mi minsize="2.4" maxsize="2.4">/</mi><mrow><mo stretchy="true" form="prefix">(</mo><mfrac><mn>1</mn><mrow><mi>M</mi><mo>−</mo><mn>1</mn></mrow></mfrac><mo>+</mo><mfrac><mn>1</mn><msup><mi>M</mi><mn>2</mn></msup></mfrac><mo>⋅</mo><mfrac><mrow><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>M</mi></munderover><mtext mathvariant="normal">Var</mtext><msup><mrow><mo stretchy="true" form="prefix">(</mo><msub><mover><mi>θ</mi><mo accent="true">̂</mo></mover><mi>i</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mn>2</mn></msup></mrow><msubsup><mtext mathvariant="normal">Var</mtext><mtext mathvariant="normal">between</mtext><mn>2</mn></msubsup></mfrac><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">
\nu = (M - 1) \left( 1 + \frac{ \frac{1}{M} \sum_{i=1}^{M} \text{Var}(\hat{\theta}_i) }{ \text{Var}_{\text{between}} } \right)^2
\bigg/
\left( \frac{1}{M - 1} + \frac{1}{M^2} \cdot \frac{ \sum_{i=1}^{M} \text{Var}(\hat{\theta}_i)^2 }{ \text{Var}_{\text{between}}^2 } \right)
</annotation></semantics></math></p>
<p>In keeping with the convention used by the U.S. Census Bureau for
published ACS estimates, fusionACS returns the 90% margin of error:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mtext mathvariant="normal">ME</mtext><mrow><mn>90</mn><mi>%</mi></mrow></msub><mo>=</mo><msub><mi>t</mi><mrow><mn>0.95</mn><mo>,</mo><mspace width="0.167em"></mspace><mi>ν</mi></mrow></msub><mo>⋅</mo><msqrt><msub><mtext mathvariant="normal">Var</mtext><mtext mathvariant="normal">combined</mtext></msub></msqrt></mrow><annotation encoding="application/x-tex">
\text{ME}_{90\%} = t_{0.95, \, \nu} \cdot \sqrt{\text{Var}_{\text{combined}}}
</annotation></semantics></math></p>
</div>
<div class="section level3">
<h3 id="interpretation-of-uncertainty">Interpretation of uncertainty<a class="anchor" aria-label="anchor" href="#interpretation-of-uncertainty"></a>
</h3>
<p>There is no universal standard for judging when the margin of error
and/or coefficient of variation are “too high”. The answer always
depends on the nature of the analysis and intended application. At a
minimum, generalized guidelines should be used to determine when and if
valid conclusions can be drawn from specific estimates; for example, see
<span class="citation">Parmenter and Lau (<a href="#ref-Parmenter2013">2013</a>)</span>, page 2.</p>
<p>It is important that analyses or reports based on fusionACS data
products communicate the authors’ chosen standards for determining when
an estimate is sufficiently reliable to draw conclusions.</p>
</div>
</div>
<div class="section level2 unnumbered">
<h2 class="unnumbered" id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h2>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
<div id="ref-Agresti1998" class="csl-entry">
Agresti, Alan, and Brent A. Coull. 1998. <span>“Approximate Is Better
Than Exact for Interval Estimation of Binomial Proportions.”</span>
<em>The American Statistician</em> 52 (2): 119–26.
</div>
<div id="ref-Barnard1999" class="csl-entry">
Barnard, John, and Donald B. Rubin. 1999. <span>“Small-Sample Degrees of
Freedom with Multiple Imputation.”</span> <em>Biometrika</em> 86 (4):
948–55. <a href="https://doi.org/10.1093/biomet/86.4.948" class="external-link">https://doi.org/10.1093/biomet/86.4.948</a>.
</div>
<div id="ref-Hahn1991" class="csl-entry">
Hahn, G. J., and W. Q. Meeker. 1991. <em>Statistical Intervals: A Guide
for Practitioners</em>. New York: Wiley.
</div>
<div id="ref-Kish1965" class="csl-entry">
Kish, Leslie. 1965. <em>Survey Sampling</em>. Wiley Series in
Probability and Mathematical Statistics. New York: Wiley.
</div>
<div id="ref-Koenker2005" class="csl-entry">
Koenker, Roger. 2005. <em>Quantile Regression</em>. Cambridge: Cambridge
University Press.
</div>
<div id="ref-Krantz2025" class="csl-entry">
Krantz, Sebastian. 2025. <em>Collapse: Advanced and Fast Data
Transformation in r</em>. <a href="https://doi.org/10.5281/zenodo.8433090" class="external-link">https://doi.org/10.5281/zenodo.8433090</a>.
</div>
<div id="ref-Lumley2010" class="csl-entry">
Lumley, Thomas. 2010. <em>Complex Surveys: A Guide to Analysis Using
r</em>. Wiley Series in Survey Methodology. Hoboken, NJ: Wiley. <a href="https://books.google.com/books?id=7skyokxvcEoC" class="external-link">https://books.google.com/books?id=7skyokxvcEoC</a>.
</div>
<div id="ref-Parmenter2013" class="csl-entry">
Parmenter, Barbara M., and Janet Lau. 2013. <span>“Estimating and
Mapping Reliability for American Community Survey Data.”</span>
https://sites.tufts.edu/gis/files/2013/11/Amercian-Community-Survey_Margin-of-error-tutorial.pdf.
</div>
<div id="ref-Rubin1987" class="csl-entry">
Rubin, Donald B. 1987. <em>Multiple Imputation for Nonresponse in
Surveys</em>. New York: Wiley.
</div>
<div id="ref-Serfling1980" class="csl-entry">
Serfling, Robert J. 1980. <em>Approximation Theorems of Mathematical
Statistics</em>. New York: Wiley.
</div>
<div id="ref-Tuccillo2023" class="csl-entry">
Tuccillo, Joseph V., Robert Stewart, Amy Rose, Nathan Trombley, Jessica
Moehl, Nicholas Nagle, and Budhendra Bhaduri. 2023. <span>“UrbanPop: A
Spatial Microsimulation Framework for Exploring Demographic Influences
on Human Dynamics.”</span> <em>Applied Geography</em> 151: 102844. <a href="https://doi.org/10.1016/j.apgeog.2022.102844" class="external-link">https://doi.org/10.1016/j.apgeog.2022.102844</a>.
</div>
<div id="ref-Tukey1977" class="csl-entry">
Tukey, John W. 1977. <em>Exploratory Data Analysis</em>. Reading, MA:
Addison-Wesley.
</div>
<div id="ref-Ummel2024" class="csl-entry">
Ummel, Kevin, Miguel Poblete-Cazenave, Karthik Akkiraju, Nick Graetz,
Hero Ashman, Cora Kingdon, Steven Herrera Tenorio, Aaryaman Sunny
Singhal, Daniel Aldana Cohen, and Narasimha D. Rao. 2024.
<span>“Multidimensional Well-Being of US Households at a Fine Spatial
Scale Using Fused Household Surveys.”</span> <em>Scientific Data</em> 11
(142). <a href="https://doi.org/10.1038/s41597-023-02788-7" class="external-link">https://doi.org/10.1038/s41597-023-02788-7</a>.
</div>
<div id="ref-Census2020" class="csl-entry">
U.S. Census Bureau. 2020. <span>“American Community Survey: Design and
Methodology (Chapter 12: Accuracy of the Data).”</span> U.S. Department
of Commerce, Economics; Statistics Administration, U.S. Census Bureau;
<a href="https://www.census.gov/programs-surveys/acs/methodology/design-and-methodology.html" class="external-link uri">https://www.census.gov/programs-surveys/acs/methodology/design-and-methodology.html</a>.
</div>
</div>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Kevin Ummel.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.3.</p>
</div>

    </footer>
</div>





  </body>
</html>
