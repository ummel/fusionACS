[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "fusionACS",
    "section": "",
    "text": "Project overview\nA large amount of data concerning the experiences and wellbeing of American households is collected by surveys. Household surveys typically focus on a single topic – e.g. finances, housing, health – and field independent and relatively small samples. As a result, data users are often constrained by the particular variables and spatial resolution available in a single survey.\nThe fusionACS data science platform (Ummel et al. 2024) helps address this problem by statistically “fusing” microdata from disparate surveys to simulate a single, integrated, high-resolution survey. The resulting fused microdata can be used to perform analyses that would otherwise be impossible. At its core, fusionACS seeks to maximize the amount of useful information that can be extracted from the existing array of U.S. survey data.\n\n\nMethodology\nfusionACS uses the American Community Survey (ACS) – the largest U.S. household survey – as the “data backbone” of the fusion process. Variables in “donor” surveys are fused onto ACS Public Use Microdata Sample (PUMS) microdata to produce simulated values for variables unique to the donor. This generates probabilistic estimates of how ACS respondents might have answered a donor survey’s questionnaire. Respondent characteristics that are common to both the donor and the ACS (e.g. income, age, household size) – as well as spatial information that can be merged to both (e.g. characteristics of the local built environment) – are used as predictors variables in LightGBM machine learning models (Ke et al. 2017).\nIn 2025, an enhanced version of fusionACS was introduced that integrates UrbanPop, a synthetic population data product produced by Oak Ridge National Laboratory (Tuccillo et al. 2023). UrbanPop provides probabilistic estimates of the location (block group) of each ACS respondent household. The fusionACS + UrbanPop platform is able to generate estimates for any donor survey variable for locales as small as individual census block groups.\nSee the Methodology page for more information.\n\n\nInputs\nTo do…\nSee the Inputs page for more information.\n\n\nOutputs\nTo do…\nSee the Outputs page for more information.\n\n\nUse cases\nSee the Publications page for more information.\n\n\n\n\n\nReferences\n\nKe, Guolin, Qi Meng, Thomas Finley, Taifeng Wang, Wei Chen, Weidong Ma, Qiwei Ye, and Tie-Yan Liu. 2017. “LightGBM: A Highly Efficient Gradient Boosting Decision Tree.” In Advances in Neural Information Processing Systems 30, 3149–57. https://papers.nips.cc/paper/6907-lightgbm-a-highly-efficient-gradient-boosting-decision-tree.\n\n\nTuccillo, Joseph V., Robert Stewart, Amy Rose, Nathan Trombley, Jessica Moehl, Nicholas Nagle, and Budhendra Bhaduri. 2023. “UrbanPop: A Spatial Microsimulation Framework for Exploring Demographic Influences on Human Dynamics.” Applied Geography 151: 102844. https://doi.org/10.1016/j.apgeog.2022.102844.\n\n\nUmmel, Kevin, Miguel Poblete-Cazenave, Karthik Akkiraju, Nick Graetz, Hero Ashman, Cora Kingdon, Steven Herrera Tenorio, Aaryaman Sunny Singhal, Daniel Aldana Cohen, and Narasimha D. Rao. 2024. “Multidimensional Well-Being of US Households at a Fine Spatial Scale Using Fused Household Surveys.” Scientific Data 11 (142). https://doi.org/10.1038/s41597-023-02788-7."
  },
  {
    "objectID": "faq.html",
    "href": "faq.html",
    "title": "Frequently Asked Questions",
    "section": "",
    "text": "Can other donor surveys be fused?\nYes. In principle, any U.S. household- or person-level national survey circa 2005 or later is a candidate for fusion."
  },
  {
    "objectID": "publications.html",
    "href": "publications.html",
    "title": "Publications",
    "section": "",
    "text": "Citing fusionACS\nAny use of fusionACS outputs should cite Ummel et al. (2024):\n\nUmmel, Kevin, Miguel Poblete-Cazenave, Karthik Akkiraju, Nick Graetz, Hero Ashman, Cora Kingdon, Steven Herrera Tenorio, Aaryaman Sunny Singhal, Daniel Aldana Cohen, and Narasimha D. Rao. 2024. “Multidimensional Well-Being of US Households at a Fine Spatial Scale Using Fused Household Surveys.” Scientific Data 11 (142). https://doi.org/10.1038/s41597-023-02788-7.\n\nAny use of fusionACS estimates for locales smaller than Public Use Microdata Areas (PUMA’s) should also cite Tuccillo et al. (2023):\n\nTuccillo, Joseph V., Robert Stewart, Amy Rose, Nathan Trombley, Jessica Moehl, Nicholas Nagle, and Budhendra Bhaduri. 2023. “UrbanPop: A Spatial Microsimulation Framework for Exploring Demographic Influences on Human Dynamics.” Applied Geography 151: 102844. https://doi.org/10.1016/j.apgeog.2022.102844.\n\n\n\nPublications using fusionACS\n\nBrown, M., Becker, J. M., Carbone, J. C., Goforth, T., McFarland, J., Nock, D., Pitman, K., & Steinberg, D. 2024. Tax credits for clean electricity: The distributional impacts of supply-push policies in the power sector. Journal of the Association of Environmental and Resource Economists, 11(S1), S199–S229. https://doi.org/10.1086/730923"
  },
  {
    "objectID": "inputs.html",
    "href": "inputs.html",
    "title": "Data Inputs",
    "section": "",
    "text": "Donor surveys\nDescription of the data inputs."
  },
  {
    "objectID": "methodology.html",
    "href": "methodology.html",
    "title": "Methodology",
    "section": "",
    "text": "A fusionACS analysis consists of a request for an estimate (mean, median, sum, proportion, or count) of a particular variable across one or more sub-populations. For example, “Mean household electricity consumption in Chicago, by census tract”; or “Proportion of low-income households in Atlanta without air conditioning”. In addition to a point estimate, fusionACS also returns the associated uncertainty or margin of error.\nThere are two fundamental sources of uncertainty when performing an analysis using fusionACS data. First, there is uncertainty in the fused outcomes for ACS respondent households; i.e. uncertainty in the values predicted by the underlying machine learning models. Second, there is uncertainty in the assigned weight for each respondent; i.e. uncertainty about how often a sampled respondent “type” appears in the actual population.\nOutcome uncertainty is captured through the production of M unique implicates during the fusion process; each implicate is a plausible simulation of the fused variables given uncertainty in the underlying models. Weighting uncertainty is captured through the use of R unique replicates; each replicate provides plausible household sample weights given uncertainty in the characteristics of the population.\nTaken together, a fusionACS analysis computes across \\(k = M \\cdot R\\) unique samples, each representing a plausible combination of outcomes and weights.\n\n\nFor any given fusionACS analysis, the point estimates and associated margin of error are calculated using the technique of Rubin (1987). The point estimate, \\(\\bar{\\theta}\\), is the mean of the individual estimates calculated for each of the \\(k\\) samples:\n\\[\n\\bar{\\theta} = \\frac{1}{k} \\sum_{i=1}^{k} \\hat{\\theta}_i\n\\] The variance of \\(\\bar{\\theta}\\) is calculated by “pooling” the variance both within and between samples:\n\\[\n\\text{Var}_{\\text{combined}} = \\frac{1}{k} \\sum_{i=1}^{k} \\text{Var}( \\hat{\\theta}_i ) + \\left( 1 + \\frac{1}{k} \\right) \\text{Var}_{\\text{between}}\n\\] where \\(\\text{Var}_{\\text{between}}\\) is the “between-sample” variance of the individual estimates:\n\\[\n\\text{Var}_{\\text{between}} = \\frac{1}{k - 1} \\sum_{i=1}^{k} \\left( \\hat{\\theta}_i - \\bar{\\theta} \\right)^2\n\\]\nand \\(\\text{Var}( \\hat{\\theta}_i )\\) refers to the “within-sample” variances of the individual estimates; i.e. the square of the standard error (\\(\\text{SE}( \\hat{\\theta} )^2\\)).\n\n\n\nThe calculation of within-sample standard errors depends on the type of estimate requested. To calculate the standard error of a mean estimate for a sample of \\(n\\) observations with frequency weights \\(w_i\\):\n\\[\nSE(\\hat{\\theta}_{\\text{mean}}) = \\sqrt{ \\frac{ \\sum w_i (x_i - \\bar{x}_w)^2 }{ \\sum w_i - 1 } \\cdot \\frac{1}{n_{\\text{eff}}} }\n\\] where \\(\\bar{x}_w\\) is the weighted mean and \\(n_{\\text{eff}}\\) is the effective sample size calculated from the observation weights:\n\\[\nn_{\\text{eff}} = \\frac{ \\left( \\sum w_i \\right)^2 }{ \\sum w_i^2 }\n\\]\nThe use of \\(n_{\\text{eff}}\\) (rather than sample size \\(n\\)) accounts for additional uncertainty introduced by variance in the weights themselves. In general, the smaller the target population the greater the “unevenness” of the weights, leading to \\(n_{\\text{eff}}&lt;n\\), and a corresponding increase in the standard error (Kish 1965; Lumley 2010).\nFor medians, bootstrapping and non-parametric simulation are possible but require significant computation (Hahn and Meeker 1991). Given the necessity of computational efficiency in the fusionACS context, the standard error of the median instead uses the approximation of Tukey (1977):\n\\[\nSE(\\hat{\\theta}_{\\text{median}}) \\approx SE(\\hat{\\theta}_{\\text{mean}})  \\cdot \\frac{\\pi}{2}\n\\]\nTo calculate the standard error of a proportion within a sample of \\(n\\) observations with frequency weights \\(w_i\\):\n\\[\nSE(\\hat{\\theta}_{\\text{proportion}}) = \\sqrt{ \\frac{ \\hat{p}(1 - \\hat{p}) }{ n_{\\text{eff}} } }\n\\]\nwhere \\(\\hat{p}\\) is a (weighted) proportion estimated from the observed sample and \\(n_{\\text{eff}}\\) is calculated as above.\nFor sums (numerical case) and counts (categorical case), the standard error is a multiple of the standard error of the mean and proportion, respectively:\n\\[\nSE(\\hat{\\theta}_{\\text{sum}}) = SE(\\hat{\\theta}_{\\text{mean}}) \\cdot \\sum w_i\n\\]\n\\[\nSE(\\hat{\\theta}_{\\text{count}}) = SE(\\hat{\\theta}_{\\text{proportion}}) \\cdot \\sum w_i\n\\]\n\n\n\nHaving calculated \\(\\text{Var}_{\\text{combined}}\\) and its component variances, the degrees of freedom is calculated using the formula of Barnard and Rubin (1999). Compared to the original Rubin (1987) degrees of freedom, this formulation allows for unequal within-sample variances and is more accurate for small samples.\n\\[\n\\nu = (k - 1) \\left( 1 + \\frac{ \\frac{1}{k} \\sum_{i=1}^{k} \\text{Var}(\\hat{\\theta}_i) }{ \\text{Var}_{\\text{between}} } \\right)^2\n\\bigg/\n\\left( \\frac{1}{k - 1} + \\frac{1}{k^2} \\cdot \\frac{ \\sum_{i=1}^{k} \\text{Var}(\\hat{\\theta}_i)^2 }{ \\text{Var}_{\\text{between}}^2 } \\right)\n\\]\nIn keeping with the convention used by the U.S. Census Bureau for published ACS estimates, fusionACS returns both the 90% margin of error and the coefficient of variation.\n\\[\n\\text{ME}_{90\\%} = t_{0.95, \\, \\nu} \\cdot \\sqrt{\\text{Var}_{\\text{combined}}}\n\\] \\[\n\\text{CV} = 100 \\times \\frac{\\text{ME}_{90\\%} / 1.645}{|\\bar{\\theta}|}\n\\]\nThe latter provides a scale-independent measure of estimate reliability."
  },
  {
    "objectID": "methodology.html#estimating-uncertainty",
    "href": "methodology.html#estimating-uncertainty",
    "title": "Methodology",
    "section": "",
    "text": "A fusionACS analysis consists of a request for an estimate (mean, median, sum, proportion, or count) of a particular variable across one or more sub-populations. For example, “Mean household electricity consumption in Chicago, by census tract”; or “Proportion of low-income households in Atlanta without air conditioning”. In addition to a point estimate, fusionACS also returns the associated uncertainty or margin of error.\nThere are two fundamental sources of uncertainty when performing an analysis using fusionACS data. First, there is uncertainty in the fused outcomes for ACS respondent households; i.e. uncertainty in the values predicted by the underlying machine learning models. Second, there is uncertainty in the assigned weight for each respondent; i.e. uncertainty about how often a sampled respondent “type” appears in the actual population.\nOutcome uncertainty is captured through the production of M unique implicates during the fusion process; each implicate is a plausible simulation of the fused variables given uncertainty in the underlying models. Weighting uncertainty is captured through the use of R unique replicates; each replicate provides plausible household sample weights given uncertainty in the characteristics of the population.\nTaken together, a fusionACS analysis computes across \\(k = M \\cdot R\\) unique samples, each representing a plausible combination of outcomes and weights.\n\n\nFor any given fusionACS analysis, the point estimates and associated margin of error are calculated using the technique of Rubin (1987). The point estimate, \\(\\bar{\\theta}\\), is the mean of the individual estimates calculated for each of the \\(k\\) samples:\n\\[\n\\bar{\\theta} = \\frac{1}{k} \\sum_{i=1}^{k} \\hat{\\theta}_i\n\\] The variance of \\(\\bar{\\theta}\\) is calculated by “pooling” the variance both within and between samples:\n\\[\n\\text{Var}_{\\text{combined}} = \\frac{1}{k} \\sum_{i=1}^{k} \\text{Var}( \\hat{\\theta}_i ) + \\left( 1 + \\frac{1}{k} \\right) \\text{Var}_{\\text{between}}\n\\] where \\(\\text{Var}_{\\text{between}}\\) is the “between-sample” variance of the individual estimates:\n\\[\n\\text{Var}_{\\text{between}} = \\frac{1}{k - 1} \\sum_{i=1}^{k} \\left( \\hat{\\theta}_i - \\bar{\\theta} \\right)^2\n\\]\nand \\(\\text{Var}( \\hat{\\theta}_i )\\) refers to the “within-sample” variances of the individual estimates; i.e. the square of the standard error (\\(\\text{SE}( \\hat{\\theta} )^2\\)).\n\n\n\nThe calculation of within-sample standard errors depends on the type of estimate requested. To calculate the standard error of a mean estimate for a sample of \\(n\\) observations with frequency weights \\(w_i\\):\n\\[\nSE(\\hat{\\theta}_{\\text{mean}}) = \\sqrt{ \\frac{ \\sum w_i (x_i - \\bar{x}_w)^2 }{ \\sum w_i - 1 } \\cdot \\frac{1}{n_{\\text{eff}}} }\n\\] where \\(\\bar{x}_w\\) is the weighted mean and \\(n_{\\text{eff}}\\) is the effective sample size calculated from the observation weights:\n\\[\nn_{\\text{eff}} = \\frac{ \\left( \\sum w_i \\right)^2 }{ \\sum w_i^2 }\n\\]\nThe use of \\(n_{\\text{eff}}\\) (rather than sample size \\(n\\)) accounts for additional uncertainty introduced by variance in the weights themselves. In general, the smaller the target population the greater the “unevenness” of the weights, leading to \\(n_{\\text{eff}}&lt;n\\), and a corresponding increase in the standard error (Kish 1965; Lumley 2010).\nFor medians, bootstrapping and non-parametric simulation are possible but require significant computation (Hahn and Meeker 1991). Given the necessity of computational efficiency in the fusionACS context, the standard error of the median instead uses the approximation of Tukey (1977):\n\\[\nSE(\\hat{\\theta}_{\\text{median}}) \\approx SE(\\hat{\\theta}_{\\text{mean}})  \\cdot \\frac{\\pi}{2}\n\\]\nTo calculate the standard error of a proportion within a sample of \\(n\\) observations with frequency weights \\(w_i\\):\n\\[\nSE(\\hat{\\theta}_{\\text{proportion}}) = \\sqrt{ \\frac{ \\hat{p}(1 - \\hat{p}) }{ n_{\\text{eff}} } }\n\\]\nwhere \\(\\hat{p}\\) is a (weighted) proportion estimated from the observed sample and \\(n_{\\text{eff}}\\) is calculated as above.\nFor sums (numerical case) and counts (categorical case), the standard error is a multiple of the standard error of the mean and proportion, respectively:\n\\[\nSE(\\hat{\\theta}_{\\text{sum}}) = SE(\\hat{\\theta}_{\\text{mean}}) \\cdot \\sum w_i\n\\]\n\\[\nSE(\\hat{\\theta}_{\\text{count}}) = SE(\\hat{\\theta}_{\\text{proportion}}) \\cdot \\sum w_i\n\\]\n\n\n\nHaving calculated \\(\\text{Var}_{\\text{combined}}\\) and its component variances, the degrees of freedom is calculated using the formula of Barnard and Rubin (1999). Compared to the original Rubin (1987) degrees of freedom, this formulation allows for unequal within-sample variances and is more accurate for small samples.\n\\[\n\\nu = (k - 1) \\left( 1 + \\frac{ \\frac{1}{k} \\sum_{i=1}^{k} \\text{Var}(\\hat{\\theta}_i) }{ \\text{Var}_{\\text{between}} } \\right)^2\n\\bigg/\n\\left( \\frac{1}{k - 1} + \\frac{1}{k^2} \\cdot \\frac{ \\sum_{i=1}^{k} \\text{Var}(\\hat{\\theta}_i)^2 }{ \\text{Var}_{\\text{between}}^2 } \\right)\n\\]\nIn keeping with the convention used by the U.S. Census Bureau for published ACS estimates, fusionACS returns both the 90% margin of error and the coefficient of variation.\n\\[\n\\text{ME}_{90\\%} = t_{0.95, \\, \\nu} \\cdot \\sqrt{\\text{Var}_{\\text{combined}}}\n\\] \\[\n\\text{CV} = 100 \\times \\frac{\\text{ME}_{90\\%} / 1.645}{|\\bar{\\theta}|}\n\\]\nThe latter provides a scale-independent measure of estimate reliability."
  },
  {
    "objectID": "methodology.html#computational-efficiency",
    "href": "methodology.html#computational-efficiency",
    "title": "Methodology",
    "section": "Computational efficiency",
    "text": "Computational efficiency"
  },
  {
    "objectID": "methodology.html#interpretation-of-uncertainty",
    "href": "methodology.html#interpretation-of-uncertainty",
    "title": "Methodology",
    "section": "Interpretation of uncertainty",
    "text": "Interpretation of uncertainty\nThere is no universal standard for judging when the margin of error and/or coefficient of variation are “too high”. The answer always depends on the nature of the analysis and intended application. At a minimum, generalized guidelines should be used to determine when and if valid conclusions can be drawn from specific estimates; for example, see Parmenter and Lau (2013), page 2.\nIt is important that analyses or reports based on fusionACS data products communicate the authors’ chosen standards for determining when an estimate is sufficiently reliable to draw conclusions."
  },
  {
    "objectID": "team.html",
    "href": "team.html",
    "title": "Team",
    "section": "",
    "text": "Team members\nAbout the team members"
  },
  {
    "objectID": "outputs.html",
    "href": "outputs.html",
    "title": "Data Outputs",
    "section": "",
    "text": "Outputs\nData outputs available for visualization or download."
  }
]